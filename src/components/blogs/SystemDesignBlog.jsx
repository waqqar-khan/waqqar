import "../../App.css";

import Pagination from "../../feature/Pagination";
import usePagination from "../../hooks/usePagination";

const SystemDesignBlog = () => {
  const systemDesignQnaList = [
    {
      question: "What is system design and why is it important?",
      answer:
        "System design is the process of defining the architecture, modules, interfaces, and data for a system to satisfy specified requirements. It involves breaking down complex systems into smaller, manageable components, each with specific responsibilities. It is crucial because it ensures that the system will be robust, scalable, and maintainable. Good system design helps in addressing potential bottlenecks, scaling issues, and ensures that the system meets both functional and non-functional requirements effectively.",
    },
    {
      question: "What are the key principles of system design?",
      answer:
        "Key principles of system design include modularity, scalability, reliability, availability, and maintainability. Modularity involves dividing the system into distinct modules with well-defined interfaces. Scalability ensures that the system can handle increased loads by adding resources. Reliability is about designing systems to operate correctly under expected conditions. Availability ensures the system is operational and accessible when needed. Maintainability focuses on designing systems that are easy to update and manage over time.",
    },
    {
      question:
        "What is the difference between vertical scaling and horizontal scaling?",
      answer:
        "Vertical scaling, or scaling up, involves increasing the capacity of a single server, such as adding more CPU, memory, or storage to handle increased load. Horizontal scaling, or scaling out, involves adding more servers to a system to distribute the load and increase capacity. Vertical scaling can be limited by the maximum capacity of a single machine, whereas horizontal scaling can be more flexible and fault-tolerant, as it distributes the load across multiple machines.",
    },
    {
      question: "How does load balancing work and what are its types?",
      answer:
        "Load balancing distributes incoming network traffic across multiple servers to ensure no single server becomes overwhelmed. This improves performance and reliability. Types of load balancing include round-robin, where requests are distributed evenly in a circular order; least connections, where requests are sent to the server with the fewest active connections; and IP hash, where requests are distributed based on the client’s IP address. Load balancers can be implemented at various levels, including DNS, application, and network layers.",
    },
    {
      question: "What is the CAP theorem and how does it affect system design?",
      answer:
        "The CAP theorem states that a distributed system can achieve at most two out of the following three properties: Consistency, Availability, and Partition Tolerance. Consistency means every read receives the most recent write. Availability means every request receives a response, even if it’s not the most recent. Partition Tolerance means the system continues to operate despite network partitions. System designers must make trade-offs based on the specific requirements of their applications, balancing these properties according to their needs.",
    },
    {
      question:
        "What is the role of a database index and how does it improve query performance?",
      answer:
        "A database index is a data structure that improves the speed of data retrieval operations on a database table. It works like a book index, allowing the database to quickly locate the rows matching a query condition without scanning the entire table. Indexes can significantly reduce query response times by providing a more efficient path to the desired data, especially for large datasets. However, they also come with overhead costs for storage and can affect the performance of write operations.",
    },
    {
      question:
        "What are microservices and how do they differ from monolithic architectures?",
      answer:
        "Microservices are an architectural style where an application is composed of small, independent services that communicate over a network. Each service is focused on a specific business function and can be developed, deployed, and scaled independently. In contrast, a monolithic architecture is a single, tightly-coupled application where all components are interconnected and deployed together. Microservices offer benefits like scalability, flexibility, and easier maintenance, but they also introduce challenges such as service coordination and increased complexity.",
    },
    {
      question:
        "How does a distributed cache work and what are its advantages?",
      answer:
        "A distributed cache is a caching system where data is stored across multiple servers or nodes, rather than on a single server. This approach enhances performance and scalability by distributing the load and reducing the risk of a single point of failure. Advantages include improved data retrieval times, reduced database load, and better fault tolerance. Distributed caches like Redis and Memcached can handle high volumes of requests and provide a centralized cache that is accessible from multiple application instances.",
    },
    {
      question:
        "What is the purpose of a message queue and how does it support system decoupling?",
      answer:
        "A message queue is a communication method used to enable asynchronous communication between different parts of a system. It allows messages or tasks to be sent from one component to another without requiring immediate processing. This decouples components by allowing them to operate independently and handle messages at their own pace. Message queues support system decoupling by providing a buffer between producers and consumers, allowing systems to handle varying loads and improve reliability by mitigating the impact of component failures.",
    },
    {
      question:
        "What are the main types of databases and when should you use each?",
      answer:
        "Databases can be broadly categorized into relational databases (RDBMS) and non-relational databases (NoSQL). RDBMS, like MySQL and PostgreSQL, use structured query language (SQL) and are ideal for applications with complex queries and transactions requiring ACID (Atomicity, Consistency, Isolation, Durability) properties. NoSQL databases, like MongoDB and Cassandra, offer flexible schemas and are suited for unstructured data, scalability, and high-performance read and write operations. Choosing between them depends on the application’s data model, consistency requirements, and scalability needs.",
    },
    {
      question:
        "How does a Content Delivery Network (CDN) improve web performance?",
      answer:
        "A Content Delivery Network (CDN) improves web performance by distributing content across multiple geographically dispersed servers. When a user requests content, the CDN serves it from the nearest server, reducing latency and load times. CDNs cache static assets like images, stylesheets, and scripts, which offloads traffic from the origin server and improves scalability. They also provide redundancy and fault tolerance, enhancing availability and reliability of content delivery.",
    },
    {
      question:
        "What is eventual consistency and how does it differ from strong consistency?",
      answer:
        "Eventual consistency is a consistency model where updates to a distributed system are propagated to all nodes eventually, but not necessarily immediately. It guarantees that all nodes will converge to the same state given enough time. Strong consistency, on the other hand, ensures that all nodes see the same data at the same time, providing immediate consistency after a write operation. Eventual consistency is often used in distributed systems for better availability and scalability, while strong consistency is used when immediate accuracy is critical.",
    },
    {
      question:
        "What is a Service-Level Agreement (SLA) and why is it important in system design?",
      answer:
        "A Service-Level Agreement (SLA) is a formal contract between a service provider and a customer that defines the expected level of service, including performance metrics, uptime guarantees, and response times. SLAs are important in system design because they set clear expectations for service delivery, ensure accountability, and provide a basis for measuring and managing service quality. They help align system design and operational practices with business goals and customer requirements.",
    },
    {
      question:
        "How do you handle system failures and ensure high availability?",
      answer:
        "Handling system failures and ensuring high availability involves implementing redundancy, failover mechanisms, and robust monitoring. Redundancy involves having backup systems or components that can take over in case of failure. Failover mechanisms automatically switch to backup systems when a failure is detected. Monitoring tools track system health and performance, enabling proactive response to issues. High availability is achieved by designing systems with minimal downtime and quick recovery capabilities, ensuring continuous operation even during failures.",
    },
    {
      question: "What are distributed transactions and how do they work?",
      answer:
        "Distributed transactions are transactions that involve multiple distributed systems or databases. They ensure that a set of operations across different systems either all succeed or all fail, maintaining data consistency. Distributed transactions typically use protocols like Two-Phase Commit (2PC) or consensus algorithms to coordinate and commit changes across all involved systems. These protocols involve a preparation phase where changes are proposed, and a commit phase where the changes are finalized, ensuring atomicity and consistency across distributed components.",
    },
    {
      question:
        "What is the role of API gateways in microservices architectures?",
      answer:
        "API gateways serve as a single entry point for managing and routing requests in microservices architectures. They handle tasks such as request routing, load balancing, authentication, and rate limiting. API gateways aggregate responses from multiple microservices, providing a unified API to clients. They also enable monitoring and logging of API calls, making it easier to manage and secure the microservices ecosystem while simplifying client interactions with the system.",
    },
    {
      question: "How does database sharding work and what are its benefits?",
      answer:
        "Database sharding is a method of distributing data across multiple database instances or shards to improve scalability and performance. Each shard holds a subset of the data, and queries are directed to the appropriate shard based on the shard key. Benefits of sharding include improved performance through parallel processing, increased capacity for handling large datasets, and enhanced fault tolerance by isolating failures to individual shards. However, sharding also introduces complexity in terms of data distribution and query management.",
    },
    {
      question:
        "What is the concept of a 'Service Mesh' and how does it enhance microservices communication?",
      answer:
        "A Service Mesh is an infrastructure layer that manages communication between microservices. It provides features such as service discovery, load balancing, traffic management, and security without requiring changes to application code. By deploying a service mesh, you can gain insights into service interactions, enforce policies, and handle complex routing rules more efficiently. It enhances microservices communication by decoupling the application logic from the communication concerns, leading to more manageable and resilient systems.",
    },
    {
      question: "How do you implement and manage versioning in RESTful APIs?",
      answer:
        "Versioning in RESTful APIs is implemented to manage changes and maintain compatibility with existing clients. Common strategies include URL versioning (e.g., /api/v1/resource), header versioning (using custom headers), and query parameter versioning (e.g., /api/resource?version=1). Versioning allows for incremental changes without breaking existing clients and enables developers to provide multiple API versions simultaneously. It is essential to document versions clearly and handle deprecated versions gracefully to ensure smooth transitions for API consumers.",
    },
    {
      question:
        "What is the purpose of rate limiting and how can it be implemented?",
      answer:
        "Rate limiting is a technique used to control the number of requests a client can make to a server within a specific time period. It helps prevent abuse, ensures fair usage, and protects server resources. Rate limiting can be implemented using token buckets, leaky buckets, or fixed windows algorithms. Techniques include using middleware or API gateways to enforce limits based on client IP addresses, API keys, or user accounts. Proper rate limiting ensures system stability and prevents overloading the server with excessive requests.",
    },
    {
      question: "What is data denormalization and when should it be used?",
      answer:
        "Data denormalization is the process of introducing redundancy into a database by combining tables or duplicating data to improve read performance. It is used in scenarios where complex queries or joins are frequent and can negatively impact performance. Denormalization helps reduce the need for joins, making queries faster and more efficient. However, it comes with trade-offs, including increased storage requirements and the need for additional logic to keep redundant data consistent. It is typically used in read-heavy systems where performance is a critical concern.",
    },
    {
      question:
        "What is a 'Circuit Breaker' pattern in system design and how does it improve system resilience?",
      answer:
        "The Circuit Breaker pattern is used to detect and handle failures in distributed systems by preventing a system from making requests to a failing service. It works like an electrical circuit breaker, opening the circuit when failures reach a certain threshold and allowing time for the service to recover. During this period, requests are either rejected or directed to fallback mechanisms. Once the service recovers, the circuit is closed, and normal operations resume. This pattern improves system resilience by preventing cascading failures and providing mechanisms for graceful degradation.",
    },
    {
      question: "How does data replication work and what are its types?",
      answer:
        "Data replication involves copying and maintaining data across multiple database instances to ensure consistency, availability, and disaster recovery. Types of replication include master-slave replication, where one master database handles writes and multiple slave databases handle reads; master-master replication, where multiple databases can handle both reads and writes; and multi-master replication, which allows for more complex scenarios with multiple nodes participating in both read and write operations. Each type has its trade-offs in terms of consistency, complexity, and performance.",
    },
    {
      question:
        "What are 'Hot' and 'Cold' data in system design and how should they be managed?",
      answer:
        "Hot data refers to frequently accessed or updated data that requires fast and real-time access, while cold data refers to infrequently accessed or archived data. Hot data should be stored in high-performance storage systems for quick retrieval, such as in-memory databases or SSDs. Cold data can be stored in more cost-effective, lower-performance storage systems, such as traditional disk storage or cloud storage services. Effective management involves implementing data lifecycle policies to move data between hot and cold storage based on access patterns and performance requirements.",
    },
  ];

  const {
    currentPage,
    itemsPerPage,
    totalPages,
    currentItems,
    onPageChange,
    onItemsPerPageChange,
  } = usePagination(systemDesignQnaList, 10);

  return (
    <div className="w-full max-w-4xl mx-auto p-5 md:pt-8 lg:pt-14 font-sans mt-14">
      <h1 className="italic text-2xl text-center text-purple-800 font-serif font-semibold pb-8">
        SYSTEM DESIGN BlOG
      </h1>
      {currentItems.map((qa, index) => (
        <div key={index} className="mb-5 pb-3 border-b border-gray-300">
          <h2 className="text-lg text-black">{qa.question}</h2>
          <p className="text-gray-600">{qa.answer}</p>
        </div>
      ))}
      <Pagination
        totalItems={systemDesignQnaList.length}
        itemsPerPage={itemsPerPage}
        currentPage={currentPage}
        totalPages={totalPages}
        onPageChange={onPageChange}
        onItemsPerPageChange={onItemsPerPageChange}
      />
    </div>
  );
};

export default SystemDesignBlog;
